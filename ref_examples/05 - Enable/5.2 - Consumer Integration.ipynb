{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "<div style=\"display: flex; justify-content: space-between; align-items: center; padding: 8px 16px; background: #F8F9FA; border-bottom: 2px solid #E0E0E0; margin: 0; line-height: 1;\">\n    <div style=\"font-size: 14px; color: #666;\">\n        <span style=\"font-weight: bold; color: #333;\">{SOURCE_PLATFORM} → Databricks Migration</span>\n        <span style=\"margin-left: 8px; color: #999;\">|</span>\n        <span style=\"margin-left: 8px;\">05 - Enable</span>\n    </div>\n    <div style=\"display: flex; align-items: center; gap: 8px;\">\n        <img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"24\" height=\"24\"/>\n        <span style=\"color: #999; font-size: 16px;\">→</span>\n        <img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"24\" height=\"24\"/>\n    </div>\n</div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img\n    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n    alt=\"Databricks Learning\"\n  >\n</div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "# Consumer Integration\n\n## Overview\n\nYou've successfully migrated data and workloads to Databricks. Now comes the critical phase: **operationalizing the platform for ongoing use at scale**. This module focuses on integrating the downstream consumers of your data and AI assets - from BI analysts querying dashboards to ML engineers deploying models to production.\n\n**Key Distinction:** Earlier modules *built* things; this module is about *operationalizing* and *scaling* them for ongoing use.\n\nConsumer integration encompasses:\n- **BI tool connectivity** - Connecting Tableau, Power BI, Looker, and other BI platforms to SQL Warehouses\n- **Dashboard migration** - Porting dashboards from {SOURCE_PLATFORM} to Databricks SQL or connected BI tools\n- **ML pipeline integration** - Integrating model training, feature engineering, and serving with Unity Catalog\n- **API and SDK access** - Enabling programmatic access for applications and downstream systems\n\n## Learning Objectives\n\nBy the end of this lesson, you will be able to:\n- Configure BI tool connections to Databricks SQL Warehouses\n- Migrate and validate dashboards with SLA requirements\n- Integrate ML pipelines with Unity Catalog governance\n- Implement API and SDK patterns for downstream consumers\n- Establish monitoring and SLA validation for consumer workloads"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "<div style=\"border-left: 4px solid #1976d2; background: #e3f2fd; padding: 16px 20px; border-radius: 4px; margin: 16px 0;\">\n    <div style=\"display: flex; align-items: flex-start; gap: 12px;\">\n        <span style=\"font-size: 24px;\">ℹ️</span>\n        <div>\n            <strong style=\"color: #0d47a1; font-size: 1.1em;\">Consumer Integration is about Scale and Operationalization</strong>\n            <p style=\"margin: 8px 0 0 0; color: #333;\">\n                This phase is not about proving the platform works - you've already done that in <strong>Activate</strong>. It's about enabling hundreds or thousands of users to consume data and AI assets reliably, with predictable performance and governance. Focus on <strong>self-service, monitoring, and SLA management</strong>.\n            </p>\n        </div>\n    </div>\n</div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Consumer Integration Architecture\n\nUnderstanding the consumer landscape helps you plan integration priorities and resource allocation.\n\n<br />\n\n<div class=\"mermaid\">\ngraph TB\n    subgraph \"Data & AI Platform\"\n        UC[Unity Catalog<br/>Governance Layer]\n        SQLW[SQL Warehouses<br/>BI & Analytics]\n        DLT[Delta Live Tables<br/>Pipelines]\n        FS[Feature Store<br/>ML Features]\n        MR[Model Registry<br/>ML Models]\n        MS[Model Serving<br/>Inference APIs]\n    end\n\n    subgraph \"BI Consumers\"\n        Tableau[Tableau]\n        PowerBI[Power BI]\n        Looker[Looker]\n        DBSQL[Databricks SQL<br/>Native Dashboards]\n    end\n\n    subgraph \"ML Consumers\"\n        Training[Model Training<br/>Notebooks/Jobs]\n        Serving[Application<br/>Integration]\n        Batch[Batch Inference<br/>Pipelines]\n    end\n\n    subgraph \"Application Consumers\"\n        REST[REST APIs<br/>Applications]\n        SDK[Python/R SDK<br/>Custom Tools]\n        JDBC[JDBC/ODBC<br/>Legacy Apps]\n    end\n\n    UC --> SQLW\n    UC --> FS\n    UC --> MR\n\n    SQLW --> Tableau\n    SQLW --> PowerBI\n    SQLW --> Looker\n    SQLW --> DBSQL\n\n    FS --> Training\n    MR --> MS\n    MS --> Serving\n    DLT --> Batch\n\n    SQLW --> REST\n    SQLW --> SDK\n    SQLW --> JDBC\n\n    style UC fill:#FF3621,stroke:#333,stroke-width:2px,color:#fff\n    style SQLW fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style FS fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style MR fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n</div>\n\n<script type=\"module\">\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({ startOnLoad: true, theme: 'default' });\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Consumer Segmentation and Prioritization\n\nNot all consumers are equal. Segment by business criticality, usage patterns, and migration complexity to prioritize integration efforts.\n\n| Consumer Type | Characteristics | Priority | Migration Complexity |\n|--------------|-----------------|----------|---------------------|\n| **Executive Dashboards** | Low query volume, high visibility, strict SLAs | **High** | Medium - require validation |\n| **Operational BI** | High concurrency, ad-hoc queries, self-service | **High** | Low - standard connectors |\n| **Production ML Models** | Real-time inference, strict latency SLAs | **Critical** | High - requires validation |\n| **Batch Analytics** | Scheduled reports, predictable load | Medium | Low - scheduled jobs |\n| **Data Science Exploration** | Variable usage, flexible SLAs | Medium | Low - notebook migration |\n| **Application APIs** | Programmatic access, authentication requirements | High | Medium - SDK integration |\n\n### Prioritization Framework\n\nUse this framework to sequence consumer migrations:\n\n| Factor | Weight | Evaluation Criteria |\n|--------|--------|---------------------|\n| **Business Impact** | 40% | Revenue impact, executive visibility, regulatory requirements |\n| **Usage Volume** | 25% | Query frequency, user count, data volume |\n| **SLA Strictness** | 20% | Latency requirements, uptime guarantees, business continuity |\n| **Migration Risk** | 15% | Technical complexity, dependencies, rollback difficulty |\n\n**Example Scoring:**\n- **Critical (80-100 points):** Migrate immediately, dedicated resources, phased rollout\n- **High (60-79 points):** Early migration wave, standard validation\n- **Medium (40-59 points):** Mid-wave migration, batch processing\n- **Low (0-39 points):** Late wave or self-service migration"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "# BI Tool Connectivity\n\n## Overview\n\nBI tools are typically the highest-volume consumers of your data platform. Databricks SQL provides a standards-based connection layer optimized for BI workloads with enterprise-grade performance, concurrency, and governance.\n\n### SQL Warehouse Architecture for BI\n\nSQL Warehouses are optimized compute clusters designed specifically for BI and SQL analytics workloads.\n\n<br />\n\n<div class=\"mermaid\">\ngraph TB\n    subgraph \"BI Tools\"\n        Tableau[Tableau<br/>Partner Connect]\n        PowerBI[Power BI<br/>Partner Connect]\n        Looker[Looker<br/>JDBC/ODBC]\n        Other[Other BI Tools<br/>JDBC/ODBC]\n    end\n\n    subgraph \"SQL Warehouse Layer\"\n        SW1[SQL Warehouse<br/>BI Production]\n        SW2[SQL Warehouse<br/>Executive Dashboards]\n        SW3[SQL Warehouse<br/>Ad-hoc Analysis]\n    end\n\n    subgraph \"Unity Catalog\"\n        UC[Catalog Governance<br/>Row/Column Security]\n        Cache[Result Cache<br/>Query Acceleration]\n    end\n\n    subgraph \"Delta Tables\"\n        Gold[Gold Tables<br/>Business Ready]\n    end\n\n    Tableau --> SW1\n    PowerBI --> SW1\n    Looker --> SW2\n    Other --> SW3\n\n    SW1 --> UC\n    SW2 --> UC\n    SW3 --> UC\n\n    UC --> Cache\n    Cache --> Gold\n\n    style UC fill:#FF3621,stroke:#333,stroke-width:2px,color:#fff\n    style SW1 fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style SW2 fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style SW3 fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n</div>\n\n<script type=\"module\">\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({ startOnLoad: true, theme: 'default' });\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## SQL Warehouse Types and Selection\n\nChoose the right warehouse type based on workload characteristics and budget.\n\n| Warehouse Type | Use Case | Startup Time | Cost Model | Best For |\n|----------------|----------|--------------|------------|----------|\n| **Serverless** | Production BI, dashboards, APIs | Instant | Pay per query (with idle charges) | Variable workloads, instant availability |\n| **Pro** | High-concurrency BI, analyst workloads | ~2-5 min | DBU-based with auto-scaling | Predictable BI loads, cost optimization |\n| **Classic** | Legacy compatibility, specific requirements | ~5-10 min | DBU-based | Special configurations, control plane requirements |\n\n### Warehouse Sizing Guidelines\n\n| Warehouse Size | Concurrent Users | Queries per Hour | Typical Use Case |\n|----------------|------------------|------------------|------------------|\n| **2X-Small** | 1-5 | < 100 | Development, testing |\n| **X-Small** | 5-10 | 100-500 | Small teams, departmental BI |\n| **Small** | 10-20 | 500-1,000 | Mid-size teams |\n| **Medium** | 20-40 | 1,000-5,000 | Enterprise BI, production dashboards |\n| **Large** | 40-80 | 5,000-10,000 | High-concurrency, mission-critical |\n| **X-Large+** | 80+ | 10,000+ | Extreme scale, global BI platforms |\n\n**Auto-scaling Recommendation:** Enable auto-scaling (min 1, max 3-4x min) to handle variable loads without overprovisioning."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## BI Tool Integration Patterns\n\n### Pattern 1: Partner Connect (Recommended)\n\n**Supported Tools:** Tableau, Power BI, Fivetran, dbt Cloud, others\n\nPartner Connect automates authentication, warehouse provisioning, and credential management.\n\n<div class=\"code-block\" data-language=\"bash\">\n# Partner Connect Steps (UI-based):\n# 1. Navigate to Databricks workspace → Partner Connect\n# 2. Select BI tool (e.g., Tableau, Power BI)\n# 3. Click \"Connect\" - automatic service principal creation\n# 4. Download credentials or follow OAuth flow\n# 5. Tool-specific configuration wizard completes setup\n</div>\n\n**Advantages:**\n- One-click setup with minimal configuration\n- Automatic service principal and token management\n- Tool-optimized warehouse configuration\n- Simplified credential rotation\n\n### Pattern 2: JDBC/ODBC Connection (Standard)\n\n**Supported Tools:** All JDBC/ODBC-compatible BI tools\n\nManual connection using JDBC/ODBC drivers for maximum flexibility.\n\n<div class=\"code-block\" data-language=\"bash\">\n# JDBC Connection String\njdbc:databricks://<workspace-url>:443/default;\n  transportMode=http;\n  ssl=1;\n  httpPath=/sql/1.0/warehouses/<warehouse-id>;\n  AuthMech=3;\n  UID=token;\n  PWD=<personal-access-token>\n</div>\n\n<div class=\"code-block\" data-language=\"python\">\n# Python Example using databricks-sql-connector\nfrom databricks import sql\n\nconnection = sql.connect(\n    server_hostname=\"<workspace-url>\",\n    http_path=\"/sql/1.0/warehouses/<warehouse-id>\",\n    access_token=\"<personal-access-token>\"\n)\n\ncursor = connection.cursor()\ncursor.execute(\"SELECT * FROM catalog.schema.table LIMIT 10\")\nresult = cursor.fetchall()\ncursor.close()\nconnection.close()\n</div>\n\n### Pattern 3: OAuth 2.0 (Enterprise)\n\n**Supported Tools:** Tableau, Power BI, custom applications\n\nOAuth provides user-specific authentication and fine-grained access control.\n\n<div class=\"code-block\" data-language=\"bash\">\n# OAuth Configuration Steps:\n# 1. Settings → Developer → OAuth Applications\n# 2. Create new OAuth app with redirect URIs\n# 3. Configure BI tool to use OAuth flow\n# 4. Users authenticate via Databricks workspace login\n# 5. Access inherits Unity Catalog permissions\n</div>\n\n**Advantages:**\n- User-specific auditing (no shared credentials)\n- Unity Catalog row/column security honored\n- Automatic credential refresh\n- Compliance-friendly (individual accountability)\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'bash';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## BI Tool-Specific Configuration\n\n### Tableau Integration\n\n**Connection Method:** Partner Connect (recommended) or native Databricks connector\n\n<div class=\"code-block\" data-language=\"bash\">\n# Tableau Desktop Configuration\n# 1. Connect → More → Databricks\n# 2. Enter server hostname (workspace URL)\n# 3. HTTP Path: /sql/1.0/warehouses/<warehouse-id>\n# 4. Authentication: Personal Access Token or OAuth\n# 5. Select catalog, schema, tables\n</div>\n\n**Optimization Tips:**\n- Enable **Tableau hyper extracts** for large datasets (faster initial load, scheduled refresh)\n- Use **Live connections** for real-time dashboards (query pushdown to Photon)\n- Configure **connection pooling** for high-concurrency environments\n- Leverage **Tableau Catalog** with Unity Catalog lineage for data governance\n\n### Power BI Integration\n\n**Connection Method:** Partner Connect or native connector\n\n<div class=\"code-block\" data-language=\"bash\">\n# Power BI Desktop Configuration\n# 1. Get Data → More → Databricks\n# 2. Server hostname: <workspace-url>\n# 3. HTTP Path: /sql/1.0/warehouses/<warehouse-id>\n# 4. Data Connectivity: DirectQuery (recommended) or Import\n# 5. Authentication: Personal Access Token\n</div>\n\n**Optimization Tips:**\n- Use **DirectQuery mode** for large datasets (query pushdown to Databricks)\n- Configure **incremental refresh** for Import mode to reduce data movement\n- Enable **query folding** to ensure predicates push to SQL Warehouse\n- Use **Power BI Premium** with dedicated capacity for enterprise deployments\n\n### Looker Integration\n\n**Connection Method:** JDBC with custom dialect\n\n<div class=\"code-block\" data-language=\"bash\">\n# Looker Connection Configuration\n# Database: Databricks (select from dialect dropdown)\n# Host: <workspace-url>\n# Port: 443\n# Database: <catalog-name>\n# Username: token\n# Password: <personal-access-token>\n# Additional JDBC parameters: httpPath=/sql/1.0/warehouses/<warehouse-id>\n</div>\n\n**Optimization Tips:**\n- Use **PDTs (Persistent Derived Tables)** backed by Delta tables for aggregations\n- Configure **connection pooling** with appropriate max connections\n- Leverage **aggregate awareness** to route queries to pre-aggregated tables\n- Enable **SQL Runner** for analysts to explore data directly\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'bash';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## BI Performance Optimization\n\n### Query Acceleration Techniques\n\n| Technique | What It Does | When to Use |\n|-----------|--------------|-------------|\n| **Photon Engine** | Vectorized C++ query engine | Always (included in SQL Warehouses) |\n| **Result Caching** | Caches query results for reuse | Dashboards with repeated queries |\n| **Liquid Clustering** | Automatic data layout optimization | Large fact tables with predictable query patterns |\n| **Materialized Views** | Pre-computed aggregations | Complex aggregations queried frequently |\n| **Z-Ordering** | Data skipping via co-location | High cardinality columns in filters |\n| **Predictive Optimization** | Automatic maintenance and stats | Always (background optimization) |\n\n### Dashboard-Specific Optimization\n\n<div class=\"code-block\" data-language=\"sql\">\n-- Create materialized view for dashboard aggregations\nCREATE MATERIALIZED VIEW catalog.schema.sales_summary_mv\nAS\nSELECT\n    date_trunc('day', order_date) AS order_day,\n    product_category,\n    region,\n    COUNT(*) AS order_count,\n    SUM(revenue) AS total_revenue,\n    AVG(revenue) AS avg_revenue\nFROM catalog.schema.orders\nGROUP BY date_trunc('day', order_date), product_category, region;\n\n-- Refresh schedule (automatic with serverless)\nALTER MATERIALIZED VIEW catalog.schema.sales_summary_mv\nSET TBLPROPERTIES ('pipelines.autoOptimize.managed' = 'true');\n</div>\n\n<div class=\"code-block\" data-language=\"sql\">\n-- Enable liquid clustering for large tables\nALTER TABLE catalog.schema.orders\nCLUSTER BY (order_date, customer_id);\n\n-- Clustering is automatic - no manual maintenance required\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'sql';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "# Dashboard Migration and SLA Validation\n\n## Overview\n\nDashboard migration is not just about porting visuals - it's about maintaining **business continuity** and **meeting SLA commitments** while modernizing your BI stack.\n\n### Migration Approach Decision Tree\n\n<br />\n\n<div class=\"mermaid\">\ngraph TD\n    Start[Dashboard Migration Decision] --> Complexity{Dashboard Complexity?}\n\n    Complexity -->|Simple<br/>Single table| Direct[Direct Migration<br/>Repoint connection]\n    Complexity -->|Moderate<br/>Multiple tables| Rewrite[Rewrite Queries<br/>Optimize for Databricks]\n    Complexity -->|Complex<br/>Heavy logic| Refactor[Refactor Architecture<br/>SQL + Python]\n\n    Direct --> Validate1[Validate Results]\n    Rewrite --> Validate2[Validate Results]\n    Refactor --> Validate3[Validate Results]\n\n    Validate1 --> SLA{Meets SLA?}\n    Validate2 --> SLA\n    Validate3 --> SLA\n\n    SLA -->|Yes| Deploy[Deploy to Production]\n    SLA -->|No| Optimize[Optimize Performance]\n\n    Optimize --> Retest[Retest SLA]\n    Retest --> SLA\n\n    Deploy --> Monitor[Monitor & Alert]\n\n    style Start fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    style Deploy fill:#c8e6c9,stroke:#388e3c,stroke-width:2px\n    style SLA fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n</div>\n\n<script type=\"module\">\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({ startOnLoad: true, theme: 'default' });\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Dashboard Migration Patterns\n\n| Migration Pattern | Description | Use Case | Complexity |\n|-------------------|-------------|----------|------------|\n| **Repoint** | Change connection, keep dashboard as-is | Simple dashboards, compatible SQL | Low |\n| **Rewrite** | Rebuild dashboard in same tool on Databricks | Moderate complexity, query optimization needed | Medium |\n| **Refactor** | Redesign dashboard architecture | Heavy transformations, poor performance | High |\n| **Hybrid** | Maintain legacy dashboard while building new | Critical dashboards, gradual transition | Medium |\n\n### Migration Checklist by Dashboard Type\n\n| Dashboard Type | Key Validations | Common Issues | Mitigation |\n|----------------|-----------------|---------------|------------|\n| **Executive** | Results accuracy, refresh time < SLA | Custom SQL not supported | Rewrite using Databricks SQL dialect |\n| **Operational** | Concurrency handling, real-time freshness | High query volume | Auto-scaling warehouse, result caching |\n| **Analytical** | Complex aggregations, drill-down paths | Slow aggregations | Materialized views, Photon acceleration |\n| **Embedded** | API latency, authentication flow | Token expiration | OAuth with refresh tokens |"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## SLA Definition and Validation\n\n### Defining Measurable SLAs\n\nSLAs must be **specific, measurable, and business-aligned** to validate migration success.\n\n| SLA Type | Metric | Example Target | Measurement Method |\n|----------|--------|----------------|-------------------|\n| **Query Latency** | P50, P95, P99 response time | P95 < 5 seconds | Query history analysis |\n| **Dashboard Refresh** | End-to-end refresh time | < 30 seconds | Dashboard load time |\n| **Data Freshness** | Time from source to BI | < 15 minutes | Pipeline watermarks |\n| **Availability** | Uptime percentage | 99.9% uptime | Warehouse availability metrics |\n| **Concurrency** | Simultaneous users supported | 100 concurrent users | Load testing |\n| **Accuracy** | Data validation pass rate | 100% match with source | Row count, hash comparison |\n\n### SLA Validation Framework\n\n<div class=\"code-block\" data-language=\"python\">\n# SLA Validation Script Example\nfrom databricks import sql\nimport time\nimport pandas as pd\n\ndef validate_dashboard_sla(warehouse_id, queries, p95_target_seconds=5.0):\n    \"\"\"\n    Validate dashboard SLA by running representative queries\n    and measuring P95 latency.\n    \"\"\"\n    connection = sql.connect(\n        server_hostname=dbutils.secrets.get(\"prod\", \"db-hostname\"),\n        http_path=f\"/sql/1.0/warehouses/{warehouse_id}\",\n        access_token=dbutils.secrets.get(\"prod\", \"db-token\")\n    )\n\n    latencies = []\n\n    for query in queries:\n        cursor = connection.cursor()\n        start_time = time.time()\n        cursor.execute(query)\n        results = cursor.fetchall()\n        end_time = time.time()\n\n        latency = end_time - start_time\n        latencies.append({\n            'query': query[:50],\n            'latency_seconds': latency,\n            'row_count': len(results)\n        })\n        cursor.close()\n\n    connection.close()\n\n    # Calculate percentiles\n    df = pd.DataFrame(latencies)\n    p50 = df['latency_seconds'].quantile(0.50)\n    p95 = df['latency_seconds'].quantile(0.95)\n    p99 = df['latency_seconds'].quantile(0.99)\n\n    sla_met = p95 <= p95_target_seconds\n\n    print(f\"P50 Latency: {p50:.2f}s\")\n    print(f\"P95 Latency: {p95:.2f}s\")\n    print(f\"P99 Latency: {p99:.2f}s\")\n    print(f\"SLA Met (P95 < {p95_target_seconds}s): {sla_met}\")\n\n    return sla_met, df\n\n# Example usage\ndashboard_queries = [\n    \"SELECT * FROM catalog.schema.sales_summary WHERE date >= current_date() - 7\",\n    \"SELECT product, SUM(revenue) FROM catalog.schema.orders GROUP BY product\"\n]\n\nsla_met, results = validate_dashboard_sla(\n    warehouse_id=\"abc123def456\",\n    queries=dashboard_queries,\n    p95_target_seconds=5.0\n)\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Dashboard Monitoring and Alerting\n\n### Key Metrics to Monitor\n\n| Metric | What It Measures | Alert Threshold | Action |\n|--------|------------------|----------------|--------|\n| **Query Failure Rate** | Percentage of failed queries | > 1% | Investigate error logs, check permissions |\n| **Query Duration** | P95 query latency | > SLA threshold | Optimize queries, scale warehouse |\n| **Warehouse Utilization** | Cluster load percentage | > 80% sustained | Scale up or enable auto-scaling |\n| **Queue Time** | Time queries wait in queue | > 10 seconds | Increase warehouse size or concurrency |\n| **Data Freshness** | Pipeline delay from source | > freshness SLA | Investigate pipeline delays |\n| **Error Codes** | Specific error patterns | > 10 occurrences | Fix query syntax, permissions, or data issues |\n\n### Alerting Configuration Example\n\n<div class=\"code-block\" data-language=\"python\">\n# Databricks SQL Alert Configuration\n# UI: SQL Warehouses → Query History → Create Alert\n\n# Example: Alert on slow queries\n\"\"\"\nAlert Name: Dashboard SLA Breach - Slow Queries\nQuery:\n  SELECT\n    query_id,\n    statement_text,\n    execution_duration_ms / 1000.0 AS duration_seconds,\n    user_name,\n    warehouse_id\n  FROM system.query.history\n  WHERE execution_duration_ms > 5000  -- 5 second threshold\n    AND start_time >= current_timestamp() - INTERVAL 1 HOUR\n  ORDER BY execution_duration_ms DESC\n  LIMIT 10\n\nSchedule: Every 15 minutes\nCondition: Rows returned > 0\nNotification: Slack #data-platform-alerts, Email: oncall@company.com\n\"\"\"\n</div>\n\n<div class=\"code-block\" data-language=\"python\">\n# Programmatic monitoring via SDK\nfrom databricks.sdk import WorkspaceClient\n\nw = WorkspaceClient()\n\n# Get query history for SLA monitoring\nqueries = w.sql.list_queries(\n    warehouse_id=\"abc123def456\",\n    max_results=100\n)\n\nfor query in queries:\n    if query.execution_duration_ms > 5000:  # 5 second threshold\n        print(f\"SLA breach detected: Query {query.query_id}\")\n        print(f\"Duration: {query.execution_duration_ms / 1000.0}s\")\n        print(f\"User: {query.user_name}\")\n        # Send alert via monitoring system\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "# ML Pipeline Integration with Unity Catalog\n\n## Overview\n\nMachine learning pipelines require more than just compute - they need governed access to features, models, and inference infrastructure. Unity Catalog provides unified governance across the entire ML lifecycle.\n\n### ML Lifecycle with Unity Catalog\n\n<br />\n\n<div class=\"mermaid\">\ngraph LR\n    subgraph \"Feature Engineering\"\n        Raw[Raw Data<br/>Bronze/Silver] --> FE[Feature Engineering<br/>Delta Live Tables]\n        FE --> FS[Feature Store<br/>Unity Catalog]\n    end\n\n    subgraph \"Model Training\"\n        FS --> Train[Model Training<br/>MLflow + UC]\n        Train --> MR[Model Registry<br/>Unity Catalog]\n    end\n\n    subgraph \"Model Serving\"\n        MR --> MS[Model Serving<br/>Real-time API]\n        MR --> Batch[Batch Inference<br/>Scheduled Jobs]\n    end\n\n    subgraph \"Governance\"\n        UC[Unity Catalog<br/>Permissions & Lineage]\n    end\n\n    FS -.->|Governed by| UC\n    MR -.->|Governed by| UC\n    MS -.->|Governed by| UC\n\n    style UC fill:#FF3621,stroke:#333,stroke-width:2px,color:#fff\n    style FS fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style MR fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n    style MS fill:#1b3b6f,stroke:#333,stroke-width:2px,color:#fff\n</div>\n\n<script type=\"module\">\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({ startOnLoad: true, theme: 'default' });\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Feature Store Integration\n\nUnity Catalog natively supports feature tables with lineage, versioning, and access control.\n\n### Feature Table Creation\n\n<div class=\"code-block\" data-language=\"python\">\nfrom databricks.feature_engineering import FeatureEngineeringClient\n\nfe = FeatureEngineeringClient()\n\n# Create feature table in Unity Catalog\nfe.create_table(\n    name=\"catalog.schema.customer_features\",\n    primary_keys=[\"customer_id\"],\n    df=customer_features_df,\n    description=\"Customer demographic and behavioral features for churn prediction\",\n    tags={\"team\": \"ml-platform\", \"model\": \"churn-v2\"}\n)\n</div>\n\n<div class=\"code-block\" data-language=\"python\">\n# Grant permissions to ML team\nspark.sql(\"\"\"\n    GRANT SELECT ON TABLE catalog.schema.customer_features\n    TO `ml-engineers@company.com`\n\"\"\")\n\n# Read features for training (with automatic lineage tracking)\nfeatures = fe.read_table(name=\"catalog.schema.customer_features\")\n</div>\n\n### Feature Serving for Inference\n\n<div class=\"code-block\" data-language=\"python\">\n# Create training set with feature lookups\nfrom databricks.feature_engineering import FeatureLookup\n\ntraining_set = fe.create_training_set(\n    df=labels_df,  # DataFrame with customer_id and label\n    feature_lookups=[\n        FeatureLookup(\n            table_name=\"catalog.schema.customer_features\",\n            lookup_key=\"customer_id\"\n        )\n    ],\n    label=\"churn_label\",\n    exclude_columns=[\"customer_id\"]\n)\n\n# Train model (features automatically included)\ntraining_df = training_set.load_df()\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Model Registry Integration\n\nUnity Catalog serves as the central model registry with governance, lineage, and deployment workflows.\n\n### Model Registration\n\n<div class=\"code-block\" data-language=\"python\">\nimport mlflow\nfrom mlflow import MlflowClient\n\nmlflow.set_registry_uri(\"databricks-uc\")\n\n# Train and log model\nwith mlflow.start_run() as run:\n    # Training code\n    model = train_model(training_df)\n\n    # Log model to Unity Catalog\n    mlflow.sklearn.log_model(\n        sk_model=model,\n        artifact_path=\"model\",\n        registered_model_name=\"catalog.schema.churn_classifier\"\n    )\n</div>\n\n### Model Versioning and Promotion\n\n<div class=\"code-block\" data-language=\"python\">\nclient = MlflowClient()\n\n# Get latest model version\nlatest_version = client.get_latest_versions(\n    name=\"catalog.schema.churn_classifier\",\n    stages=[\"None\"]\n)[0]\n\n# Promote to production with alias\nclient.set_registered_model_alias(\n    name=\"catalog.schema.churn_classifier\",\n    alias=\"champion\",\n    version=latest_version.version\n)\n\n# Grant serving permissions\nspark.sql(\"\"\"\n    GRANT EXECUTE ON MODEL catalog.schema.churn_classifier\n    TO `application-service-principal`\n\"\"\")\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Model Serving Patterns\n\n| Serving Pattern | Use Case | Latency | Throughput | Cost Model |\n|-----------------|----------|---------|------------|------------|\n| **Real-time (Serverless)** | Low-latency APIs (< 100ms), variable load | < 100ms | High concurrency | Pay per request |\n| **Real-time (Provisioned)** | Predictable load, cost optimization | < 200ms | Medium-high | DBU-based |\n| **Batch Inference** | Large datasets, scheduled scoring | Minutes | Very high | Job compute |\n| **Streaming Inference** | Event-driven predictions | Seconds | High | Streaming cluster |\n\n### Real-time Model Serving\n\n<div class=\"code-block\" data-language=\"python\">\n# Create Model Serving Endpoint (UI or API)\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n\nw = WorkspaceClient()\n\nw.serving_endpoints.create(\n    name=\"churn-classifier-endpoint\",\n    config=EndpointCoreConfigInput(\n        served_entities=[\n            ServedEntityInput(\n                entity_name=\"catalog.schema.churn_classifier\",\n                entity_version=\"1\",\n                workload_size=\"Small\",\n                scale_to_zero_enabled=True\n            )\n        ]\n    )\n)\n</div>\n\n### Calling the Inference API\n\n<div class=\"code-block\" data-language=\"python\">\nimport requests\nimport json\n\n# Get endpoint URL and token\nendpoint_url = \"https://<workspace-url>/serving-endpoints/churn-classifier-endpoint/invocations\"\ntoken = dbutils.secrets.get(\"prod\", \"db-token\")\n\n# Prepare inference payload\npayload = {\n    \"dataframe_records\": [\n        {\"customer_id\": \"C12345\", \"age\": 35, \"tenure_months\": 24},\n        {\"customer_id\": \"C67890\", \"age\": 42, \"tenure_months\": 6}\n    ]\n}\n\n# Call inference API\nresponse = requests.post(\n    endpoint_url,\n    headers={\"Authorization\": f\"Bearer {token}\"},\n    json=payload\n)\n\npredictions = response.json()\nprint(predictions)\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "# API and SDK Patterns for Downstream Consumers\n\n## Overview\n\nApplications, services, and custom tools need programmatic access to Databricks. Choose the right API pattern based on access requirements and security posture.\n\n### API Access Patterns\n\n<br />\n\n<div class=\"mermaid\">\ngraph TB\n    subgraph \"Consumer Applications\"\n        WebApp[Web Application]\n        Service[Microservice]\n        Tool[Custom Tool]\n        Script[Automation Script]\n    end\n\n    subgraph \"Authentication Layer\"\n        OAuth[OAuth 2.0<br/>User Context]\n        PAT[Personal Access Token<br/>Dev/Testing]\n        SP[Service Principal<br/>Production Apps]\n    end\n\n    subgraph \"Databricks APIs\"\n        SQLAPI[SQL Statement API<br/>Query Execution]\n        RESTAPI[REST API<br/>Management]\n        SDK[Python/Go SDK<br/>Type-safe Client]\n        JDBC[JDBC/ODBC<br/>Standards-based]\n    end\n\n    subgraph \"Data & Compute\"\n        Tables[Unity Catalog Tables]\n        Warehouses[SQL Warehouses]\n        Jobs[Jobs & Workflows]\n    end\n\n    WebApp --> OAuth\n    Service --> SP\n    Tool --> PAT\n    Script --> SP\n\n    OAuth --> SDK\n    PAT --> RESTAPI\n    SP --> SDK\n    SP --> SQLAPI\n\n    SDK --> Tables\n    SQLAPI --> Warehouses\n    RESTAPI --> Jobs\n\n    style SP fill:#c8e6c9,stroke:#388e3c,stroke-width:2px\n    style OAuth fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n</div>\n\n<script type=\"module\">\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({ startOnLoad: true, theme: 'default' });\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## API Authentication Methods\n\n| Method | Use Case | Security | Token Lifetime | Best For |\n|--------|----------|----------|----------------|----------|\n| **Service Principal** | Production apps, CI/CD, automation | High | Indefinite (rotatable) | Production workloads |\n| **OAuth 2.0** | User-facing apps, delegated access | Highest | 1 hour (auto-refresh) | Multi-tenant apps |\n| **Personal Access Token** | Development, testing, notebooks | Medium | Configurable (90 days default) | Dev/test only |\n\n<div style=\"border-left: 4px solid #f57c00; background: #fff3e0; padding: 16px 20px; border-radius: 4px; margin: 16px 0;\">\n    <div style=\"display: flex; align-items: flex-start; gap: 12px;\">\n        <span style=\"font-size: 24px;\">⚠️</span>\n        <div>\n            <strong style=\"color: #e65100; font-size: 1.1em;\">Never use Personal Access Tokens in production</strong>\n            <p style=\"margin: 8px 0 0 0; color: #333;\">\n                PATs are tied to individual users and don't support auditing or centralized rotation. Always use <strong>Service Principals</strong> for production applications and automation.\n            </p>\n        </div>\n    </div>\n</div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## SQL Statement API (Recommended)\n\nThe SQL Statement API is the recommended method for executing queries programmatically with robust error handling, async execution, and result pagination.\n\n### Python SDK Example\n\n<div class=\"code-block\" data-language=\"python\">\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.sdk.service.sql import StatementState\n\n# Initialize client with service principal\nw = WorkspaceClient(\n    host=\"https://<workspace-url>\",\n    client_id=dbutils.secrets.get(\"prod\", \"sp-client-id\"),\n    client_secret=dbutils.secrets.get(\"prod\", \"sp-client-secret\")\n)\n\n# Execute query asynchronously\nstatement = w.statement_execution.execute_statement(\n    warehouse_id=\"abc123def456\",\n    statement=\"SELECT * FROM catalog.schema.customers WHERE region = 'US'\",\n    wait_timeout=\"30s\"\n)\n\n# Poll for completion\nwhile statement.status.state in [StatementState.PENDING, StatementState.RUNNING]:\n    statement = w.statement_execution.get_statement(statement.statement_id)\n    time.sleep(1)\n\n# Get results\nif statement.status.state == StatementState.SUCCEEDED:\n    results = statement.result\n    for row in results.data_array:\n        print(row)\nelse:\n    print(f\"Query failed: {statement.status.error}\")\n</div>\n\n### REST API Example\n\n<div class=\"code-block\" data-language=\"bash\">\n# Execute SQL via REST API\ncurl -X POST https://<workspace-url>/api/2.0/sql/statements/ \\\n  -H \"Authorization: Bearer $DATABRICKS_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"warehouse_id\": \"abc123def456\",\n    \"statement\": \"SELECT COUNT(*) FROM catalog.schema.orders\",\n    \"wait_timeout\": \"30s\"\n  }'\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## JDBC/ODBC Connectivity\n\nStandards-based connectivity for legacy applications and tools that don't support native Databricks SDKs.\n\n### Java JDBC Example\n\n<div class=\"code-block\" data-language=\"java\">\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\n\npublic class DatabricksJDBCExample {\n    public static void main(String[] args) throws Exception {\n        String jdbcUrl = \"jdbc:databricks://<workspace-url>:443/default;\" +\n                         \"transportMode=http;\" +\n                         \"ssl=1;\" +\n                         \"httpPath=/sql/1.0/warehouses/<warehouse-id>;\" +\n                         \"AuthMech=3;\" +\n                         \"UID=token;\" +\n                         \"PWD=<service-principal-token>\";\n\n        Connection conn = DriverManager.getConnection(jdbcUrl);\n        Statement stmt = conn.createStatement();\n\n        ResultSet rs = stmt.executeQuery(\n            \"SELECT * FROM catalog.schema.products LIMIT 10\"\n        );\n\n        while (rs.next()) {\n            System.out.println(rs.getString(\"product_name\"));\n        }\n\n        rs.close();\n        stmt.close();\n        conn.close();\n    }\n}\n</div>\n\n### Python ODBC Example\n\n<div class=\"code-block\" data-language=\"python\">\nimport pyodbc\n\nconnection_string = (\n    \"Driver={Simba Spark ODBC Driver};\"\n    \"Host=<workspace-url>;\"\n    \"Port=443;\"\n    \"HTTPPath=/sql/1.0/warehouses/<warehouse-id>;\"\n    \"SSL=1;\"\n    \"ThriftTransport=2;\"\n    \"AuthMech=3;\"\n    \"UID=token;\"\n    \"PWD=<service-principal-token>\"\n)\n\nconn = pyodbc.connect(connection_string, autocommit=True)\ncursor = conn.cursor()\n\ncursor.execute(\"SELECT * FROM catalog.schema.products LIMIT 10\")\nrows = cursor.fetchall()\n\nfor row in rows:\n    print(row)\n\ncursor.close()\nconn.close()\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Rate Limiting and Best Practices\n\n### API Rate Limits\n\n| API Type | Rate Limit | Burst Limit | Throttle Behavior |\n|----------|-----------|-------------|-------------------|\n| **SQL Statement API** | 100 concurrent statements | 300 requests/min | Queue requests |\n| **REST API** | 30 requests/sec | 120 requests/sec | HTTP 429 (retry after) |\n| **JDBC/ODBC** | Warehouse dependent | Auto-scaling | Queue at warehouse |\n\n### Best Practices for Consumer Integration\n\n| Practice | Why It Matters | Implementation |\n|----------|----------------|----------------|\n| **Use Service Principals** | Avoid user dependency, support rotation | Create SP per application |\n| **Implement Retry Logic** | Handle transient failures gracefully | Exponential backoff with jitter |\n| **Cache Results** | Reduce query volume, improve latency | Application-level caching (Redis, etc.) |\n| **Query Optimization** | Minimize compute costs | Use LIMIT, filter early, avoid SELECT * |\n| **Connection Pooling** | Reduce connection overhead | Configure pool size based on concurrency |\n| **Monitoring & Alerting** | Detect issues before users complain | Track latency, errors, throughput |\n\n### Example: Retry Logic with Exponential Backoff\n\n<div class=\"code-block\" data-language=\"python\">\nimport time\nimport random\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.sdk.errors import ResourceConflict\n\ndef execute_with_retry(w, warehouse_id, statement, max_retries=3):\n    \"\"\"\n    Execute SQL with exponential backoff retry logic.\n    \"\"\"\n    for attempt in range(max_retries):\n        try:\n            result = w.statement_execution.execute_statement(\n                warehouse_id=warehouse_id,\n                statement=statement,\n                wait_timeout=\"30s\"\n            )\n            return result\n        except ResourceConflict as e:\n            if attempt == max_retries - 1:\n                raise\n            # Exponential backoff with jitter\n            wait_time = (2 ** attempt) + random.uniform(0, 1)\n            print(f\"Rate limited, retrying in {wait_time:.2f}s...\")\n            time.sleep(wait_time)\n        except Exception as e:\n            print(f\"Unexpected error: {e}\")\n            raise\n\n# Usage\nw = WorkspaceClient()\nresult = execute_with_retry(\n    w=w,\n    warehouse_id=\"abc123def456\",\n    statement=\"SELECT * FROM catalog.schema.large_table\"\n)\n</div>\n\n<link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css\" rel=\"stylesheet\" />\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js\"></script>\n\n<script>\n(function() {\n    document.querySelectorAll('.code-block').forEach(function(block) {\n        var lang = block.getAttribute('data-language') || 'python';\n        var code = block.textContent.trim();\n        var id = 'code-' + Math.random().toString(36).substr(2, 9);\n\n        block.innerHTML =\n            '<div style=\"position:relative;margin:16px 0;\">' +\n                '<button class=\"copy-btn\" style=\"position:absolute;top:8px;right:8px;padding:4px 12px;font-size:12px;background:#ddd;color:#333;border:1px solid #ccc;border-radius:4px;cursor:pointer;z-index:10;\">Copy</button>' +\n                '<pre style=\"background:#f8f8f8;border-radius:8px;padding:16px;padding-top:40px;overflow-x:auto;margin:0;border:1px solid #e0e0e0;\"><code id=\"' + id + '\" class=\"language-' + lang + '\" style=\"font-family:Consolas,Monaco,monospace;font-size:14px;\"></code></pre>' +\n            '</div>';\n\n        var codeEl = document.getElementById(id);\n        codeEl.textContent = code;\n        Prism.highlightElement(codeEl);\n\n        block.querySelector('.copy-btn').onclick = function() {\n            var t = document.createElement('textarea');\n            t.value = code;\n            document.body.appendChild(t);\n            t.select();\n            document.execCommand('copy');\n            document.body.removeChild(t);\n            this.textContent = '✓ Copied!';\n            setTimeout(() => this.textContent = 'Copy', 2000);\n        };\n    });\n})();\n</script>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "## Summary and Next Steps\n\nConsumer integration is the culmination of your migration - enabling users to extract value from the platform. Success requires:\n\n1. **BI Connectivity** - Standards-based integrations with validated performance\n2. **SLA Management** - Measurable commitments with monitoring and alerting\n3. **ML Integration** - Governed feature and model pipelines\n4. **API Access** - Secure, scalable programmatic access patterns\n\n**Key Takeaways:**\n- Segment consumers by business impact and prioritize accordingly\n- Use Partner Connect for BI tools when available\n- Validate SLAs before cutover, monitor continuously after\n- Always use Service Principals for production workloads\n- Implement retry logic and error handling for all API consumers\n\n**Next Steps:**\n\nContinue to **[5.3 - Developer Enablement and Adoption]($./5.3 - Developer Enablement and Adoption)** to learn how to scale adoption across your organization."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "<div style=\"color: #FF3621; font-weight: bold; font-size: 2em; margin-bottom: 12px;\">COURSE DEVELOPER (remove before publishing)</div>\n\n### Template Customization\n\n**Placeholders to replace:**\n- `{SOURCE_PLATFORM}` - Source platform name (Snowflake, BigQuery, Redshift, etc.)\n- `<workspace-url>` - Databricks workspace URL placeholder\n- `<warehouse-id>` - SQL Warehouse ID placeholder\n- `<service-principal-token>` - Token placeholder for examples\n\n**Platform-Specific Content to Add:**\n\n| Section | Customization Needed |\n|---------|---------------------|\n| **BI Tool Migration** | Document {SOURCE_PLATFORM}-specific dashboard features that require refactoring |\n| **SLA Comparison** | Provide typical {SOURCE_PLATFORM} vs Databricks performance benchmarks |\n| **ML Integration** | Compare {SOURCE_PLATFORM} ML capabilities with Databricks Feature Store/Model Registry |\n| **API Patterns** | Document common {SOURCE_PLATFORM} API patterns and Databricks equivalents |\n\n**Additional Resources to Include:**\n- Partner Connect documentation links for specific BI tools\n- SQL Warehouse sizing calculator or guidelines\n- Model Serving pricing calculator\n- SDK documentation references (Python, Go, Java)\n- Sample consumer integration repositories (GitHub)\n\n**Testing Recommendations:**\n- Validate all code examples in a real workspace\n- Test BI tool connections with actual Partner Connect flow\n- Verify model serving examples with deployed endpoint\n- Ensure SDK examples work with current versions"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cell-26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "",
     "isMarkdownSandbox": true
    }
   },
   "source": "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": {},
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}