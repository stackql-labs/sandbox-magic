{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "8b90e2c6-56c4-4c94-b4be-4e08869853f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; padding: 8px 16px; background: #F8F9FA; border-bottom: 2px solid #E0E0E0; margin: 0; line-height: 1;\">\n",
    "    <div style=\"font-size: 14px; color: #666;\">\n",
    "        <span style=\"font-weight: bold; color: #333;\">{SOURCE_PLATFORM} → Databricks Migration</span>\n",
    "        <span style=\"margin-left: 8px; color: #999;\">|</span>\n",
    "        <span style=\"margin-left: 8px;\">00 - Foundations</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
    "        <img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"24\" height=\"24\"/>\n",
    "        <span style=\"color: #999; font-size: 16px;\">→</span>\n",
    "        <img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"24\" height=\"24\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "533adcac-c993-407a-88f5-c709deebb6e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feef4a38-e1d0-402c-b650-34257bf873de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Why Migrate to Databricks\n",
    "\n",
    "## Overview\n",
    "\n",
    "This foundational module articulates the business and technical drivers for migrating from **{SOURCE_PLATFORM}** to **Databricks**. Understanding the \"why\" is critical for building stakeholder alignment, justifying investment, and setting realistic expectations for the migration journey.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "- Articulate the key business drivers for migration\n",
    "- Explain the technical advantages of the Databricks Lakehouse architecture\n",
    "- Identify opportunities for platform consolidation and new capabilities\n",
    "- Understand the Total Cost of Ownership (TCO) considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d075222d-afca-49a8-b0a7-1922277aa376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Business Drivers\n",
    "\n",
    "Migration decisions are rarely purely technical. Understanding the business case is essential for securing sponsorship, prioritizing workloads, and measuring success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1086fbc6-2220-49cd-b484-83bb076cbd0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Total Cost of Ownership (TCO) Optimization\n",
    "\n",
    "**Key Consideration:** When comparing TCO, evaluate these cost factors across both platforms:\n",
    "\n",
    "| Cost Factor | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|-------------|-------------------|------------|\n",
    "| **Compute pricing model** | REPLACE_SOURCE_SPECIFIC | Flexible DBU-based pricing with workload-optimized compute: All-purpose clusters for interactive/developer use, Jobs clusters for scheduled pipelines, and SQL warehouses for BI workloads - available in both classic and serverless options |\n",
    "| **Storage costs** | REPLACE_SOURCE_SPECIFIC | Data stored in **your** cloud-native object storage (S3, ADLS Gen2, GCS) using open Delta Lake format - you control retention, lifecycle policies, and avoid proprietary storage lock-in |\n",
    "| **Orchestration and ETL** | REPLACE_SOURCE_SPECIFIC | Natively integrated tooling with Lakeflow Jobs for orchestration, Lakeflow Connect for data ingestion, and Declarative Pipelines for reliable batch and streaming ETL - no additional licensing or third-party tools required |\n",
    "| **Query and Processing Efficiency** | REPLACE_SOURCE_SPECIFIC | Photon engine - a vectorized query engine included in the Databricks runtime that delivers world-class price/performance for analytics workloads |\n",
    "| **Concurrency costs** | REPLACE_SOURCE_SPECIFIC | Auto-scaling SQL warehouses (classic and serverless) support high-concurrency use cases, automatically scaling resources to match demand and scaling down when idle to minimize costs |\n",
    "\n",
    "**TCO Analysis Tips:**\n",
    "- Compare like-for-like workloads, not just list prices\n",
    "- Factor in hidden costs (data egress, premium features, support tiers, proprietary format lock-in)\n",
    "- Consider the long-term cost trajectory of each platform and open format benefits\n",
    "- Include productivity gains from unified platform (single governance with Unity Catalog, integrated ML/AI capabilities)\n",
    "- Account for reduced tooling sprawl - Databricks consolidates ETL, orchestration, BI, ML and AI on one platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75ae1ad3-4049-4763-8260-96a3941bf7a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Sovereignty\n",
    "\n",
    "**Key Consideration:** With Databricks, your data resides in __*your cloud storage account*__ (S3, ADLS Gen2, GCS) - you retain full ownership and control. With other cloud data warehouse platforms, managed table storage is entrusted to the vendor in their proprietary storage layer (to which you have no direct access) and stored in a proprietary encoding format (that can only be accessed using the vendor's proprietary interfaces).\n",
    "\n",
    "**Why This Matters:**\n",
    "\n",
    "| Aspect | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|--------|------------------------|--------------------------------|\n",
    "| **Data location** | Vendor's storage infrastructure in regions they control; you trust their attestations about where data physically resides | Your cloud provider and account, your region(s) - full visibility and control over data residency |\n",
    "| **Access control** | Dependent on vendor's identity systems and access policies; shared responsibility model weighted toward vendor | Your cloud IAM + Unity Catalog; you define and enforce access policies using your existing identity infrastructure |\n",
    "| **Data retrieval** | Subject to vendor export processes, quotas, and fees; data locked in proprietary formats until extracted | Direct access to data files (using open, interoperable formats) anytime via cloud-native APIs or any compatible tool |\n",
    "| **Compliance** | Reliant on vendor's certifications and warranties; audit evidence comes from vendor-provided reports | Your compliance posture, your audit trail; direct evidence collection using your GRC tooling and processes |\n",
    "| **Security and Attack Surface** | Multi-tenant SaaS platforms where the vendor controls both compute *and* storage present a concentrated attack surface. A single breach of the vendor's infrastructure can expose data across multiple customers simultaneously. In other words, an attack on another client of the data vendor can compromise **your** environment. | Data plane isolation in your cloud account; control plane separated from storage. Your secrets stay in your key management (AWS KMS, Azure Key Vault, GCP KMS). Your security tooling, your SIEM, your incident response timeline. |\n",
    "| **Business continuity** | Tied to vendor's availability, SLAs, and business viability; vendor acquisition, pivot, or shutdown directly impacts your data access | Data persists independent of Databricks subscription; open formats readable by dozens of engines; no single vendor dependency for data access |\n",
    "| **Exit strategy** | Export required with potential throttling, fees, and format conversion; migration projects can take months and require specialized tooling | Data is completely portable (already in open formats in your storage); switch compute engines without moving data; no export process needed |\n",
    "\n",
    "**Implications for Regulated Industries:**\n",
    "- Financial services, healthcare, and government organizations often require data to remain within their controlled infrastructure\n",
    "- Data residency requirements (GDPR, data localization laws) are easier to satisfy when you control storage location\n",
    "- Audit and forensic access doesn't depend on vendor cooperation\n",
    "- Vendor bankruptcy or service discontinuation doesn't put your data at risk\n",
    "- Security assessments and penetration testing can be performed on *your* infrastructure without vendor dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7602c4e0-fcdd-408a-870b-e1c75ee29dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Platform Consolidation\n",
    "\n",
    "**Single Source of Truth, Unified Data Platform**\n",
    "\n",
    "Many organizations operate with fragmented data systems and supporting infrastructure:\n",
    "\n",
    "**Benefits of Consolidation:**\n",
    "- Eliminate data silos and duplication\n",
    "- Single governance model across all workloads (including ML/AI products as well as data assets)\n",
    "- *\"Batteries Included\"* tooling (from ingestion through to serving)\n",
    "- Consistent metrics and definitions\n",
    "- Reduced operational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2270579-235b-433a-a95b-64ca181147d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Avoiding Vendor Lock-in\n",
    "\n",
    "The Databricks platform is built on core open source technologies, many of which Databricks created, including:\n",
    "\n",
    "- [**Apache Spark**](https://spark.apache.org/docs/latest/index.html) - Distributed processing engine for batch and streaming workloads\n",
    "- [**Delta Lake**](https://delta.io/) - Open table format with ACID transactions, time travel, and schema evolution\n",
    "- [**Apache Iceberg**](https://iceberg.apache.org/) - Open table format with cross-platform interoperability (UniForm provides automatic compatibility)\n",
    "- [**Unity Catalog**](https://www.unitycatalog.io/) - Open governance layer for data and AI assets (open sourced in 2024)\n",
    "- [**MLflow**](https://mlflow.org/) - Open source framework to build and manage AI applications and models \n",
    "\n",
    "**Open Formats vs Proprietary Formats**\n",
    "\n",
    "| Aspect | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|--------|-------------------|------------|\n",
    "| **Table formats** | Iceberg support for external tables only; managed tables use proprietary format | Delta Lake and Iceberg (open source) for both managed and external tables; UniForm enables automatic cross-format compatibility |\n",
    "| **Data encoding** | Proprietary formats - data only accessible through the vendors interfaces | Open source Parquet (columnar) format - readable by any compatible tool without vendor dependency |\n",
    "| **Query engine** | Proprietary query engine | Apache Spark (open source) with Photon acceleration for enhanced performance |\n",
    "| **Data portability** | Data export required; subject to vendor processes and potential fees | Data stored as Parquet files in your cloud storage - directly accessible without Databricks |\n",
    "| **Interoperability** | Limited to the vendors ecosystem and connectors | Native support for Iceberg, Hudi, and Parquet; Delta Sharing for cross-platform data exchange |\n",
    "| **Governance** | Proprietary metadata and access control | Unity Catalog (open source) - avoid proprietary metadata lock-in |\n",
    "| **Transparency** | Closed source - internal workings, optimizations, and roadmap decisions are opaque; you trust vendor claims without ability to verify | Open source core - inspect the code, understand behavior, contribute fixes, and influence roadmap through community participation |\n",
    "\n",
    "**Why This Matters:** Organizations investing in a data platform need assurance that their data, metadata, and processing logic aren't trapped in proprietary formats. Open source foundations mean your investment in skills, tooling, and data architecture remains portable - you're building on community standards, not a single vendor's roadmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8c7040b-1a56-4732-b517-258338f0481d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Enabling New Use Cases\n",
    "\n",
    "**AI/ML, Real-Time Analytics, and Streaming**\n",
    "\n",
    "Databricks enables workloads that may be difficult, expensive, or impossible on traditional cloud data warehouse platforms. Migration is an opportunity to modernize - not just replicate.\n",
    "\n",
    "| Use Case | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|----------|-------------------|------------|\n",
    "| **Machine Learning** | REPLACEME | Native ML Runtime with OSS packages, MLflow for experiment tracking, Feature Store, AutoML, and Model Serving - all integrated |\n",
    "| **Generative AI** | REPLACEME | Foundation Model APIs, Vector Search for RAG applications, Mosaic AI Agent Framework, AI Gateway for model management |\n",
    "| **Real-Time Streaming** | REPLACEME | Spark Structured Streaming with sub-second latency; Spark Declarative Pipelines for declarative streaming pipelines |\n",
    "| **Change Data Capture** | REPLACEME | Delta Change Data Feed with native SCD Type 1 and Type 2 support in Spark Declarative Pipelines |\n",
    "| **Data Science** | REPLACEME | Mature notebook environment with collaborative workspace, Git integration, integrated repos, and experiment tracking |\n",
    "| **Data Sharing** | REPLACEME | Delta Sharing (open protocol) - share data with any platform, no vendor lock-in |\n",
    "| **BI and Analytics** | REPLACEME | Databricks SQL with Photon - world-class price/performance; validated integrations with Tableau, Power BI, Qlik, ThoughtSpot, Sigma, Looker |\n",
    "\n",
    "**Migration as Modernization Opportunity:**\n",
    "\n",
    "Consider reengineering pipelines during migration to leverage capabilities that aren't straightforward on legacy platforms:\n",
    "- **CDC and streaming workloads** - Spark Structured Streaming and Spark Declarative Pipelines provide a standard framework for both batch and streaming\n",
    "- **SCD Type 2 tables** - Native support in Spark Declarative Pipelines vs. complex implementations on legacy platforms\n",
    "- **Unified analytics** - Data instantly available for ML, AI, and ad hoc analysis without moving data between systems\n",
    "\n",
    "**Key Question:** What new capabilities does your organization need that your current platform cannot efficiently provide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5c8964f-e777-4b2e-91ed-998544013c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Technical Drivers\n",
    "\n",
    "Beyond business considerations, technical capabilities often drive migration decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3c9c4cc-c993-41e1-884f-54ec4f34a35b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Thought Leadership and Lakehouse Architecture\n",
    "> Databricks is the Thought Leader in Modern Data Architecture\n",
    "\n",
    "While the Lakehouse concept has now been adopted industry-wide (BigQuery, Snowflake, Microsoft Fabric), Databricks originated these architectural paradigms and continues to drive innovation in this space.\n",
    "\n",
    "| Innovation | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks Origin</span> | Industry Adoption |\n",
    "|------------|--------|-------------------|\n",
    "| **Lakehouse Architecture** | Databricks coined the term and published the foundational research combining data lake flexibility with warehouse reliability | Now adopted by Snowflake, Google BigQuery, Microsoft Fabric, and others |\n",
    "| **Medallion Architecture** | Databricks introduced Bronze/Silver/Gold layering (~2019) as a design pattern for progressive data refinement | Microsoft Fabric uses identical terminology; pattern now considered industry standard |\n",
    "| **Delta Lake** | Created by Databricks, open-sourced to bring ACID transactions to data lakes | Sparked the open table format movement; competitors responded with Iceberg adoption |\n",
    "| **Unity Catalog** | Databricks developed unified governance for data and AI assets, open-sourced in 2024 | Setting the standard for lakehouse governance |\n",
    "\n",
    "**Why Thought Leadership Matters for Your Migration:**\n",
    "\n",
    "- **Proven patterns**: You're adopting architectures that have been battle-tested across thousands of enterprise deployments, not vendor retrofits\n",
    "- **Continuous innovation**: Databricks invests heavily in R&D - new capabilities (Photon, Serverless, AI/ML integration) are designed lakehouse-native, not bolted on\n",
    "- **Community momentum**: Open source foundations (Spark, Delta Lake, MLflow) mean a vast ecosystem of talent, tooling, and integrations\n",
    "- **Architecture alignment**: The platform was *built* for these patterns, not adapted to compete with them\n",
    "\n",
    "**Key Lakehouse Benefits:**\n",
    "- Single copy of data serves BI, data science, ML, and AI workloads - no data movement required\n",
    "- ACID transactions on cloud object storage with Delta Lake\n",
    "- Schema enforcement and evolution without pipeline rewrites\n",
    "- Time travel and audit history built into the table format\n",
    "- Unified batch and streaming on the same tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7565969e-79de-4f22-9918-0bcc0148cb8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Open Source Foundation\n",
    "> Built on Battle-Tested, Community-Driven Technologies\n",
    "\n",
    "Databricks is built on open source projects with massive adoption, active communities, and proven production reliability at scale.\n",
    "\n",
    "| Component | What It Is | Why It Matters |\n",
    "|-----------|------------|----------------|\n",
    "| **Apache Spark** | Distributed processing engine for batch and streaming workloads | Industry standard with 2,000+ contributors; skills transferable across any data organization; powers ETL, ML, and analytics at petabyte scale |\n",
    "| **Delta Lake** | Open table format adding reliability to data lakes | ACID transactions, time travel, schema evolution, and unified batch/streaming - created by Databricks, now an industry standard |\n",
    "| **Apache Parquet** | Columnar storage format optimized for analytics | 10x compression vs. row formats; supported by virtually every analytics tool; your data remains readable without any vendor |\n",
    "| **MLflow** | End-to-end ML lifecycle management | Track experiments, package models, manage deployments - created by Databricks, used by 18M+ monthly users across any ML platform |\n",
    "| **Apache Iceberg** | Open table format with cross-platform compatibility | UniForm enables Delta tables to be read as Iceberg - interoperability without data duplication |\n",
    "| **Unity Catalog** | Unified governance for data and AI assets | Open-sourced in 2024 - avoid proprietary metadata lock-in; portable governance across platforms |\n",
    "\n",
    "**Why Open Source Matters for Your Organization:**\n",
    "\n",
    "| Consideration | Proprietary Stack | Open Source Foundation |\n",
    "|---------------|-------------------|------------------------|\n",
    "| **Talent pool** | Limited to vendor-certified specialists | Millions of Spark/Python developers globally; skills transfer between employers |\n",
    "| **Community support** | Vendor support tiers and SLAs | Stack Overflow, GitHub, conferences, and thousands of contributors solving real problems |\n",
    "| **Innovation velocity** | Dependent on single vendor's roadmap | Community-driven innovation from Netflix, Meta, Uber, Databricks, and thousands of others |\n",
    "| **Transparency** | Closed roadmap, opaque algorithms | Open development, public issues, auditable code |\n",
    "| **Longevity** | Tied to vendor's business viability | Projects outlive any single company; Apache governance ensures continuity |\n",
    "| **Integration ecosystem** | Vendor-approved partners only | Broad ecosystem - any tool that reads Parquet/Delta can access your data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f19b1b40-c61e-4a18-aef9-d356b76c3e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Unified Governance with Unity Catalog\n",
    "\n",
    "> One Governance Layer for All Data and AI Assets\n",
    "\n",
    "Unity Catalog provides unified governance across your entire data and AI estate - tables, files, ML models, notebooks, and dashboards - all managed through a single, open-source catalog that was purpose-built for the lakehouse.\n",
    "\n",
    "| Capability | What It Does | Why It Matters |\n",
    "|------------|--------------|----------------|\n",
    "| **Unified Access Control** | Single permission model across all data assets using standard SQL GRANT/REVOKE syntax | No more managing separate access policies for tables, files, and ML models; one policy applies everywhere |\n",
    "| **Fine-Grained Security** | Table, column, and row-level security with attribute-based access control | Protect sensitive data at the most granular level; dynamic data masking without duplicating data |\n",
    "| **Automatic Data Lineage** | Column-level lineage tracking captured automatically from all workloads | Understand data origins, trace issues to source, satisfy regulatory requirements without manual documentation |\n",
    "| **Comprehensive Audit Logging** | Every data access and operation recorded with full context | Answer \"who accessed what, when, and how\" for compliance; feed directly to your SIEM |\n",
    "| **Data Discovery & Search** | Search, browse, tag, and document all data assets with AI-powered suggestions | Find trusted data across the organization; reduce duplicate datasets and shadow IT |\n",
    "| **Delta Sharing** | Share data with external consumers using an open protocol - no proprietary connectors | Cross-organization collaboration without data copies; recipients don't need Databricks |\n",
    "| **Lakehouse Federation** | Query external data sources (PostgreSQL, MySQL, Snowflake, etc.) through Unity Catalog | Unified governance even for data that hasn't migrated yet; single pane of glass |\n",
    "\n",
    "**Comparison with {SOURCE_PLATFORM}:**\n",
    "\n",
    "| Aspect | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Unity Catalog</span> |\n",
    "|--------|-------------------|---------------|\n",
    "| **Native catalog** | REPLACEME | Purpose-built, unified catalog for data and AI assets |\n",
    "| **Access control model** | REPLACEME | Fine-grained attribute-based access control (ABAC) with inheritance; table/column/row-level security |\n",
    "| **Data lineage** | REPLACEME | Automatic column-level lineage captured from all workloads - no manual instrumentation |\n",
    "| **ML/AI governance** | REPLACEME | Native governance for ML models, features, and endpoints - same policies as data |\n",
    "| **Cross-platform federation** | REPLACEME | Lakehouse Federation queries external catalogs (including Snowflake) with unified governance |\n",
    "| **External data sharing** | REPLACEME | Delta Sharing (open protocol) - share with any platform without vendor lock-in |\n",
    "| **Open source** | REPLACEME | Unity Catalog open-sourced in 2024 - avoid proprietary metadata lock-in |\n",
    "\n",
    "**Key Differentiator:** Unity Catalog governs not just data, but the entire AI lifecycle - ML models, feature tables, model endpoints, and AI agents - under the same unified permission model. As AI becomes central to data platforms, governance that spans both data and AI is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e228a00d-b45d-4ef6-956b-4dffc6491610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Multi-Language Support\n",
    "\n",
    "> One Platform, Any Language - Meet Your Teams Where They Are\n",
    "\n",
    "Databricks pioneered the notebook interface as a first-class citizen for data work - an approach now adopted by Snowflake, BigQuery, and other platforms. Unlike single-language environments, Databricks lets SQL analysts, Python engineers, R statisticians, and Scala developers collaborate in the same workspace, on the same data, with seamless interoperability.\n",
    "\n",
    "| Language | Primary Use Cases | Why It Matters |\n",
    "|----------|-------------------|----------------|\n",
    "| **SQL** | BI analysts, data analysts, reporting, ad-hoc queries | Lowest barrier to entry; analysts productive immediately without learning new languages |\n",
    "| **Python** | Data engineering, ML/AI, automation, general purpose | Most popular data language; vast ecosystem of libraries (pandas, scikit-learn, PyTorch) |\n",
    "| **R** | Statistical analysis, academic research, biostatistics | Preferred by statisticians and researchers; rich visualization and statistical packages |\n",
    "| **Scala** | Performance-critical Spark applications, low-level optimization | Native Spark language; maximum performance for complex distributed workloads |\n",
    "\n",
    "**Flexibility and Interoperability:**\n",
    "\n",
    "| Capability | What It Enables |\n",
    "|------------|-----------------|\n",
    "| **Mixed-language notebooks** | Combine SQL, Python, R, and Scala cells in a single notebook - use the right language for each task |\n",
    "| **Seamless data handoff** | Query results from SQL flow directly into Python DataFrames; no export/import steps |\n",
    "| **Shared compute** | All languages run on the same clusters, accessing the same data with the same permissions |\n",
    "| **Collaborative workspaces** | Data engineers write Python ETL, analysts query results in SQL, data scientists build models in R - all on one platform |\n",
    "| **Git integration** | Version control notebooks in any language; enable CI/CD workflows for all team members |\n",
    "| **Language-specific libraries** | Install PyPI, CRAN, or Maven packages as needed; no artificial constraints on tooling |\n",
    "\n",
    "**Comparison with {SOURCE_PLATFORM}:**\n",
    "\n",
    "| Aspect | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|--------|-------------------|---------------|\n",
    "| **Primary language** | REPLACEME | SQL, Python, R, and Scala as equal first-class citizens |\n",
    "| **Notebook experience** | REPLACEME | Pioneered notebooks for data; mature collaborative environment with real-time co-editing |\n",
    "| **Mixed-language workflows** | REPLACEME | Native support for multi-language notebooks; seamless variable sharing between cells |\n",
    "| **Package ecosystem** | REPLACEME | Full access to PyPI, CRAN, Maven; cluster-scoped or notebook-scoped libraries |\n",
    "| **IDE integration** | REPLACEME | Connect VS Code, PyCharm, RStudio, or any JDBC/ODBC tool |\n",
    "\n",
    "**Key Benefit:** Your organization doesn't have to standardize on a single language or retrain teams. SQL analysts stay in SQL, Python engineers use Python, and everyone shares the same governed data and compute resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4b1a458-188a-464b-b02f-efce41670ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Price/Performance Leadership\n",
    "\n",
    "> Do More With Less - Industry-Leading Price/Performance Without the Tuning Overhead\n",
    "\n",
    "Databricks consistently delivers top-tier price/performance in independent benchmarks. This isn't about raw speed alone - it's about getting more value from every dollar of compute spend while reducing the operational burden on your teams.\n",
    "\n",
    "**What Drives Databricks Price/Performance:**\n",
    "\n",
    "| Capability | Business Impact |\n",
    "|------------|-----------------|\n",
    "| **Photon Engine** | Next-generation query engine delivers 2-8x faster performance on SQL and ETL workloads - same code, lower costs |\n",
    "| **Liquid Clustering** | Automatic data organization eliminates manual table maintenance; queries find data faster without DBA intervention |\n",
    "| **Deletion Vectors** | Efficient handling of updates and deletes without rewriting entire files - critical for GDPR/CCPA compliance workloads |\n",
    "| **Predictive Optimization** | Databricks automatically optimizes your tables in the background - no scheduled maintenance jobs to manage |\n",
    "| **Serverless Compute** | Instant startup, automatic scaling, zero infrastructure management, efficient incremental refresh for materialized views - pay only for what you use |\n",
    "\n",
    "**TCO Impact:**\n",
    "\n",
    "| Factor | Traditional Approach | Databricks Advantage |\n",
    "|--------|---------------------|----------------------|\n",
    "| **Compute efficiency** | Pay for provisioned capacity regardless of utilization | Photon extracts more throughput per compute unit; serverless scales to zero |\n",
    "| **Performance tuning** | Dedicated DBAs tuning queries, indexes, and clustering | Automatic optimization - engineering time spent on business value, not maintenance |\n",
    "| **Table maintenance** | Scheduled jobs for vacuuming, compaction, statistics | Predictive Optimization handles it automatically in the background |\n",
    "| **Concurrency scaling** | Overprovision to handle peak loads | Auto-scaling SQL warehouses match capacity to demand in real-time |\n",
    "| **Time to insight** | Slow queries delay business decisions | Faster queries mean faster answers - competitive advantage |\n",
    "\n",
    "**Comparison with {SOURCE_PLATFORM}:**\n",
    "\n",
    "| Aspect | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> {SOURCE_PLATFORM}</span> | <span style=\"white-space: nowrap;\"><img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"20\" height=\"20\" style=\"vertical-align: middle;\"> Databricks</span> |\n",
    "|--------|-------------------|---------------|\n",
    "| **Query engine** | REPLACEME | Photon - vectorized C++ engine included in the runtime at no extra cost |\n",
    "| **Data organization** | REPLACEME | Liquid Clustering - automatic, incremental, no partition management |\n",
    "| **Table maintenance** | REPLACEME | Predictive Optimization - automatic vacuuming, compaction, and statistics |\n",
    "| **Update/delete efficiency** | REPLACEME | Deletion Vectors - surgical updates without full file rewrites |\n",
    "| **Price/performance benchmarks** | REPLACEME | Consistently ranked top in independent TPC-DS style evaluations |\n",
    "\n",
    "> **Migration Note:** Actual performance gains depend on workload characteristics. We recommend benchmarking your specific queries during assessment to quantify expected improvements and build a data-driven business case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4955bea1-6239-4818-a4d0-efa0b1b3cd49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building the Business Case\n",
    "\n",
    "> Align Technical Value with Business Outcomes\n",
    "\n",
    "A successful migration requires more than technical justification - it requires alignment across stakeholders who measure success differently. This section helps you frame the conversation for each audience and build a compelling, defensible business case.\n",
    "\n",
    "---\n",
    "\n",
    "### Stakeholder Alignment\n",
    "\n",
    "Different stakeholders evaluate migration through different lenses. Tailor your message accordingly:\n",
    "\n",
    "| Stakeholder | What They Care About | How Databricks Addresses It |\n",
    "|-------------|----------------------|----------------------------|\n",
    "| **CFO / Finance** | TCO reduction, license cost predictability, OpEx vs CapEx, ROI timeline | Flexible DBU pricing, reduced tooling sprawl, serverless eliminates overprovisioning, open formats avoid exit fees |\n",
    "| **CTO / Architect** | Technical capabilities, scalability, future-proofing, integration complexity | Open source foundation, lakehouse architecture, multi-cloud support, API-first design |\n",
    "| **CDO / Data Leader** | Governance, compliance, data quality, lineage, regulatory readiness | Unity Catalog provides unified governance; automatic lineage; audit logging for SOX, GDPR, HIPAA |\n",
    "| **CISO / Security** | Data sovereignty, access control, attack surface, incident response | Data stays in your cloud account; fine-grained ABAC; integration with your IAM and SIEM |\n",
    "| **Data Engineers** | Developer experience, CI/CD, debugging, maintainability | Notebooks + IDE support, Git integration, Spark Declarative Pipelines, collaborative workflows |\n",
    "| **Data Scientists** | ML capabilities, experiment tracking, model deployment, collaboration | MLflow, Feature Store, Model Serving, AutoML - all natively integrated |\n",
    "| **Business Users** | Query performance, reliability, self-service access, time to insight | Photon acceleration, Databricks SQL, governed self-service with Unity Catalog |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Questions to Answer\n",
    "\n",
    "Before seeking approval, ensure you have clear, defensible answers to these questions:\n",
    "\n",
    "| Question | Why It Matters | How to Answer It |\n",
    "|----------|----------------|------------------|\n",
    "| **Why now?** | Establishes urgency and relevance | Contract renewal timing, scaling challenges, new AI/ML requirements, security incidents, or competitive pressure |\n",
    "| **What's the cost of inaction?** | Reframes migration as risk mitigation, not just opportunity | Quantify: rising license costs, technical debt accumulation, missed business opportunities, compliance gaps |\n",
    "| **What's the total cost of ownership?** | CFO's primary concern - needs apples-to-apples comparison | Include: compute, storage, egress, tooling, personnel, training, and opportunity costs |\n",
    "| **What new capabilities do we gain?** | Justifies investment beyond cost parity | AI/ML integration, real-time streaming, unified governance, open formats - capabilities that enable new revenue or efficiency |\n",
    "| **What are the risks?** | Demonstrates due diligence; builds confidence | Identify migration complexity, timeline, skill gaps, and business continuity - then present mitigation strategies |\n",
    "| **How do we measure success?** | Creates accountability and tracks ROI | Define KPIs: cost per query, pipeline reliability, time to insight, developer productivity, compliance audit results |\n",
    "\n",
    "---\n",
    "\n",
    "### Building Your Business Case Document\n",
    "\n",
    "A compelling business case typically includes:\n",
    "\n",
    "| Section | Content |\n",
    "|---------|---------|\n",
    "| **Executive Summary** | One-page overview: problem, solution, expected outcomes, investment required |\n",
    "| **Current State Assessment** | Pain points, costs, limitations, risks of current platform |\n",
    "| **Future State Vision** | Target architecture, new capabilities enabled, alignment with business strategy |\n",
    "| **Financial Analysis** | 3-year TCO comparison, ROI projections, sensitivity analysis |\n",
    "| **Risk Assessment** | Technical, operational, and business risks with mitigation plans |\n",
    "| **Implementation Roadmap** | Phased approach, milestones, resource requirements, timeline |\n",
    "| **Success Metrics** | KPIs, measurement methodology, reporting cadence |\n",
    "\n",
    "---\n",
    "\n",
    "> **Next Step:** Use the frameworks in this module to conduct stakeholder interviews and gather the inputs needed for your business case. The subsequent modules will provide detailed guidance on assessment, planning, and execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "c14fc043-4f1e-4360-b690-dde29e859d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"color: #FF3621; font-weight: bold; font-size: 2em; margin-bottom: 12px;\">COURSE DEVELOPER (remove before publishing)</div>\n",
    "\n",
    "### Source Specific Considerations\n",
    "\n",
    "REPLACEME: Document platform-specific migration drivers, including:\n",
    "- Specific cost comparison data\n",
    "- Feature gaps that drive migration\n",
    "- Common pain points with the Source Platform\n",
    "- Success stories from similar migrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "db3d271c-d2f2-4c31-b8d5-ba5dc90c265f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<!-- NEXT ONLY -->\n",
    "<div style=\"display:flex;gap:16px;margin:24px 0\">\n",
    "  <div style=\"flex:1\"></div>\n",
    "  <a href=\"$./0.2 - Migration Maturity Model\" style=\"flex:1;border:1px solid #e0e0e0;border-radius:8px;padding:16px 20px;text-decoration:none;text-align:right\">\n",
    "    <span style=\"display:block;font-size:12px;color:#666;margin-bottom:4px\">Next</span>\n",
    "    <span style=\"display:block;font-size:16px;font-weight:600;color:#1a5276\">Migration Maturity Model »</span>\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eece539-23f1-4d45-8a45-d616a14e88b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0.1 - Why Migrate to Databricks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
