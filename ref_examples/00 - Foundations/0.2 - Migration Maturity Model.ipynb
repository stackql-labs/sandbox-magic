{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "9729ca34-146a-494d-bbb2-7484d1c784bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; padding: 8px 16px; background: #F8F9FA; border-bottom: 2px solid #E0E0E0; margin: 0; line-height: 1;\">\n",
    "    <div style=\"font-size: 14px; color: #666;\">\n",
    "        <span style=\"font-weight: bold; color: #333;\">{SOURCE_PLATFORM} → Databricks Migration</span>\n",
    "        <span style=\"margin-left: 8px; color: #999;\">|</span>\n",
    "        <span style=\"margin-left: 8px;\">00 - Foundations</span>\n",
    "    </div>\n",
    "    <div style=\"display: flex; align-items: center; gap: 8px;\">\n",
    "        <img src=\"https://cdn.simpleicons.org/snowflake/29B5E8\" width=\"24\" height=\"24\"/>\n",
    "        <span style=\"color: #999; font-size: 16px;\">→</span>\n",
    "        <img src=\"https://cdn.simpleicons.org/databricks/FF3621\" width=\"24\" height=\"24\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28fd5783-f094-4772-99c1-53c0536c787f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b971f44-cabc-4d6e-8e0f-dc5d1aa6c842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Migration Maturity Model\n",
    "\n",
    "## Overview\n",
    "\n",
    "Migration from **{SOURCE_PLATFORM}** to **Databricks** is a journey, not a single event. This module introduces a six-stage maturity model that provides a structured framework for planning, executing, and measuring migration progress.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "- Describe the six stages of migration maturity\n",
    "- Identify key activities and outcomes for each stage\n",
    "- Assess your organization's current position in the migration journey\n",
    "- Understand dependencies between stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53e68c35-8cce-491a-b22f-d82042ec97d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Why a Maturity Model?\n",
    "\n",
    "**Migration Is Not a Single Task**\n",
    "\n",
    "A {SOURCE_PLATFORM} to Databricks migration **cannot be treated as a single technical task** like exporting tables or translating SQL. It is a journey that unfolds over time as multiple parts of the platform are migrated and validated.\n",
    "\n",
    "**Benefits of a Phased Approach**\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Reduced Risk** | Each phase validates before proceeding |\n",
    "| **Measurable Progress** | Clear milestones and success criteria |\n",
    "| **Stakeholder Alignment** | Everyone understands current state |\n",
    "| **Rollback Capability** | Can pause or reverse at defined points |\n",
    "| **Resource Planning** | Different skills needed at each stage |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "d286a27b-7279-4104-9cb2-88d303521833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Migration Maturity Model\n",
    "<br />\n",
    "<div style=\"color: #FF3621; font-weight: bold; font-size: 1.1em; margin-bottom: 12px;\">A Structured Framework for Managing Migration Complexity and Risk</div>\n",
    "\n",
    "The Migration Maturity Model provides a phased approach to migrating from {SOURCE_PLATFORM} to Databricks. Each stage has clear entry criteria, deliverables, and exit gates - ensuring you progress methodically while maintaining business continuity.\n",
    "\n",
    "<br />\n",
    "<div class=\"mermaid\"> \n",
    "flowchart LR\n",
    "    S0[\"Stage 1<br/><b>ASSESS</b><br/><i>Inventory & Strategy</i>\"]\n",
    "    S1[\"Stage 2<br/><b>COEXIST</b><br/><i>Interoperability</i>\"]\n",
    "    S2[\"Stage 3<br/><b>REPLICATE</b><br/><i>Data Sync & Pipelines</i>\"]\n",
    "    S3[\"Stage 4<br/><b>CUTOVER</b><br/><i>Workload Transition</i>\"]\n",
    "    S4[\"Stage 5<br/><b>VALIDATE</b><br/><i>Stabilization & UAT</i>\"]\n",
    "    S5[\"Stage 6<br/><b>DECOMMISSION</b><br/><i>Retirement & Savings</i>\"]\n",
    "    S0 --> S1 --> S2 --> S3 --> S4 --> S5\n",
    "    style S0 fill:#E8F4FD,stroke:#5A9BD5,stroke-width:2px\n",
    "    style S1 fill:#E5F5F3,stroke:#5BA8A0,stroke-width:2px\n",
    "    style S2 fill:#EFF6E8,stroke:#7CB342,stroke-width:2px\n",
    "    style S3 fill:#FFF8E6,stroke:#E6AC00,stroke-width:2px\n",
    "    style S4 fill:#FFEFE8,stroke:#E86A4A,stroke-width:2px\n",
    "    style S5 fill:#FFE8E5,stroke:#D94530,stroke-width:2px \n",
    "</div> \n",
    "\n",
    "<script type=\"module\"> import mermaid from \"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs\"; mermaid.initialize({ startOnLoad: true, theme: \"default\" }); </script>\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20abf49c-dde5-43ec-a851-232b1c04b96e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 1: Assessment & Discovery\n",
    "\n",
    "**Goal:** Understand the current {SOURCE_PLATFORM} environment before any migration work begins\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Tools |\n",
    "|----------|-------------|-------|\n",
    "| **Workload Profiling** | Analyze query patterns, compute usage, costs | REPLACEME Profiler, Lakebridge |\n",
    "| **Complexity Scoring** | T-shirt sizing: Low → Very Complex | Assessment matrices |\n",
    "| **Code Inventory** | DDLs, Views, Stored Procs, Functions, Tasks | Code analyzers |\n",
    "| **Data Dependency Mapping** | Upstream/downstream dependencies | Lineage tools |\n",
    "| **Security Audit** | Roles, permissions, policies | Governance review |\n",
    "\n",
    "### Key Outcomes\n",
    "\n",
    "✅  Complete inventory of {SOURCE_PLATFORM} objects  \n",
    "✅  Complexity and effort estimates  \n",
    "✅  Prioritized migration candidates  \n",
    "✅  Risk assessment  \n",
    "✅  Resource requirements  \n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "✅  All databases, schemas, and objects inventoried  \n",
    "✅  Workload complexity scored  \n",
    "✅  Dependencies mapped  \n",
    "✅  Migration strategy selected  \n",
    "✅  Work breakdown structure created  \n",
    "\n",
    "> **Note:** No data or pipelines are migrated in this stage. This is purely discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d255c35-5397-4bf7-9664-b76b4556de8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 2: Coexistence & Interoperability\n",
    "\n",
    "**Goal:** Establish patterns for running both platforms during transition\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Pattern |\n",
    "|----------|-------------|----------|\n",
    "| **Parallel Operation** | Both platforms running simultaneously | Shared workloads |\n",
    "| **Catalog Federation** | Unity Catalog Foreign Catalogs | Query federation |\n",
    "| **Bridge Formats** | Iceberg tables readable by both | Data interoperability |\n",
    "| **Shared Storage** | Common cloud storage layer | S3/ADLS/GCS |\n",
    "| **External Orchestration** | Single orchestrator for both platforms | Airflow, etc. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eafe9287-bad4-4804-b41a-29211c00f932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 3: Replication & Synchronization\n",
    "\n",
    "**Goal:** Move data to Databricks and establish sync patterns\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Latency |\n",
    "|----------|-------------|----------|\n",
    "| **One-Time Offload** | Historical/static data bulk load | One-time |\n",
    "| **Snapshot Migration** | COPY INTO → Parquet → Delta | Batch |\n",
    "| **Scheduled Sync** | Periodic incremental loads | Hours |\n",
    "| **CDC Sync** | Continuous change data capture | Minutes/Seconds |\n",
    "| **Schema Sync** | DDL changes propagated | As needed |\n",
    "\n",
    "### Replication Decision Matrix\n",
    "\n",
    "| Data Type | Recommended Pattern | Rationale |\n",
    "|-----------|---------------------|------------|\n",
    "| Historical/Archive | Snapshot (one-time) | Static, no updates |\n",
    "| Reference/Dimension | Scheduled (daily) | Low change frequency |\n",
    "| Transactional | CDC (real-time) | High change frequency |\n",
    "| Aggregate/Reporting | Scheduled (hourly) | Batch-oriented |\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "✅  Schema migration complete  \n",
    "✅  Historical data loaded  \n",
    "✅  Sync patterns established and running  \n",
    "✅  Data validation passing  \n",
    "✅  Gold layer available in Databricks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b8ec30c-dd5e-4539-9801-8eb821d1bf49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Stage 4: Cutover/Go-Live\n",
    "\n",
    "**Goal:** Migrate production workloads to Databricks\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Duration |\n",
    "|----------|-------------|----------|\n",
    "| **Parallel Runs** | Both platforms processing same workloads | 1-2 weeks |\n",
    "| **Pipeline Migration** | Convert ETL/ELT to Databricks | Per workload |\n",
    "| **Query Refactoring** | Adapt SQL for Spark SQL | Per query |\n",
    "| **Validation** | Automated comparison (row counts, sums) | Continuous |\n",
    "| **Traffic Switching** | Redirect consumers to Databricks | Phased |\n",
    "\n",
    "### Cutover Patterns\n",
    "\n",
    "| Pattern | Risk | Rollback | Best For |\n",
    "|---------|------|----------|----------|\n",
    "| **Blue-Green** | Low | Easy | Critical workloads |\n",
    "| **Canary** | Low | Easy | High-volume workloads |\n",
    "| **Parallel Run** | Low | Easy | Validation-heavy |\n",
    "| **Big-Bang** | High | Hard | Simple environments |\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "✅  Pipelines running in Databricks  \n",
    "✅  Query results validated against source  \n",
    "✅  Performance meets or exceeds baseline  \n",
    "✅  Rollback procedures tested  \n",
    "✅  Production readiness criteria met  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e1059b2-23c3-4785-bee8-e3567ea146ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Stage 5: Validation & Stabilization\n",
    "\n",
    "**Goal:** Confirm correctness, performance, and user acceptance\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Owner |\n",
    "|----------|-------------|-------|\n",
    "| **Data Validation** | Row counts, checksums, sampling | Engineering |\n",
    "| **Performance Benchmarking** | Compare against baseline | Engineering |\n",
    "| **User Acceptance Testing** | Business validation | Business users |\n",
    "| **BI Dashboard Repointing** | Connect tools to Databricks | BI team |\n",
    "| **Runbook Documentation** | Operational procedures | Operations |\n",
    "\n",
    "### Validation Checks\n",
    "\n",
    "| Check | Method | Threshold |\n",
    "|-------|--------|----------|\n",
    "| **Row count** | `COUNT(*)` comparison | Exact match |\n",
    "| **Numeric sums** | `SUM()` on key columns | Within tolerance |\n",
    "| **Distinct counts** | `COUNT(DISTINCT)` | Exact match |\n",
    "| **Sample records** | Hash comparison | 100% match |\n",
    "| **Business rules** | Custom validation queries | Pass/Fail |\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "✅  All data validation checks passing  \n",
    "✅  Performance meets SLAs  \n",
    "✅  UAT sign-off received  \n",
    "✅  BI tools repointed  \n",
    "✅  Runbooks complete  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "311ace7a-966c-4bf5-9213-02ee2ec43ef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Stage 6: Decommissioning\n",
    "\n",
    "**Goal:** Retire {SOURCE_PLATFORM} and optimize Databricks\n",
    "\n",
    "### Key Activities\n",
    "\n",
    "| Activity | Description | Owner |\n",
    "|----------|-------------|-------|\n",
    "| **Pipeline Deprecation** | Shut down source pipelines | Engineering |\n",
    "| **Data Archival** | Archive per retention policy | Data governance |\n",
    "| **Access Revocation** | Disable user/service accounts | Security |\n",
    "| **License Termination** | End contracts | Procurement |\n",
    "| **Cost Reconciliation** | Final cost comparison | Finance |\n",
    "\n",
    "### Decommissioning Checklist\n",
    "\n",
    "✅  All pipelines deprecated in {SOURCE_PLATFORM}  \n",
    "✅  Data archived per retention policy  \n",
    "✅  User access revoked  \n",
    "✅  Service accounts disabled  \n",
    "✅  Contract/license termination initiated  \n",
    "✅  Final cost reconciliation complete  \n",
    "✅  Audit documentation preserved  \n",
    "✅  Retrospective completed  \n",
    "\n",
    "### Next Steps (Post-Migration)\n",
    "\n",
    "✅  Continous optimization (liquid clustering, predictive optimization, cost optimization and right sizing)  \n",
    "✅  New capability enablement (GenAI, streaming, ML)  \n",
    "✅  Training and enablement programs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aadb55a-baab-4653-821f-74f12e6ec060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Migration Anti-Patterns\n",
    "\n",
    "Learning from failed migrations is as important as following best practices. These anti-patterns have derailed countless data platform migrations - recognizing them early can save months of rework and significant budget overruns.\n",
    "\n",
    "| Anti-Pattern | Risk Level | What Happens | How to Avoid |\n",
    "|--------------|------------|--------------|--------------|\n",
    "| **Skipping Assessment** | Critical | Incomplete scope discovery leads to missed dependencies, surprise complexity, and blown timelines - \"unknown unknowns\" surface mid-migration | Invest in thorough profiling (Snowflake Profiler, Lakebridge); map all workloads, data flows, and downstream consumers before writing a single line of migration code |\n",
    "| **Big-Bang Migration** | Critical | Attempting to migrate everything at once with a single cutover date - no rollback path, extended outages, and catastrophic failure modes | Adopt phased migration by workload, schema, or business domain; maintain parallel operation; ensure rollback procedures are documented and tested |\n",
    "| **Premature Decommission** | Critical | Retiring {SOURCE_PLATFORM} before downstream dependencies are migrated or data retention requirements are satisfied | Maintain source platform until all consumers are migrated; archive data per retention policies; get explicit sign-off from all stakeholder groups |\n",
    "| **Lift-and-Shift Mentality** | High | Migrating existing architecture 1:1 without leveraging Databricks capabilities - you inherit legacy technical debt and miss the opportunity to modernize | Treat migration as a transformation, not a relocation; adopt medallion architecture, Unity Catalog governance, and Spark Declarative Pipelines rather than replicating legacy patterns |\n",
    "| **No Parallel Validation** | High | Cutting over to Databricks without running both platforms in parallel - data quality issues surface in production, eroding user trust | Run parallel pipelines for 1-2 weeks minimum; implement automated validation (row counts, checksums, business rules); require sign-off before deprecating source |\n",
    "| **Ignoring Change Management** | Medium | Focusing only on technical migration while neglecting user training, communication, and organizational readiness | Develop training programs, update documentation, communicate timeline and impact; involve end users early in UAT |\n",
    "| **Underestimating Governance** | Medium | Migrating data without replicating (or improving) access controls, lineage tracking, and compliance requirements | Map existing security model to Unity Catalog; validate RBAC/ABAC policies; ensure audit logging meets compliance needs before cutover |\n",
    "| **Going Dark on Stakeholders** | Medium | Poor communication during migration leads to shadow IT, resistance, and parallel efforts that undermine the project | Establish regular status updates, stakeholder checkpoints, and escalation paths; celebrate milestones to maintain momentum |\n",
    "\n",
    "**Key Insight:** The most successful migrations treat the project as an opportunity to modernize, not just relocate. Organizations that simply replicate their legacy architecture in Databricks miss the transformative benefits of the lakehouse - and often end up with higher costs and complexity than they started with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "ff0e4d4f-221d-4508-91c7-cc0995a6d803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"display: flex; gap: 16px; margin: 24px 0;\">\n",
    "  <a href=\"$./0.1 - Why Migrate to Databricks\" style=\"flex: 1; border: 1px solid #e0e0e0; border-radius: 8px; padding: 16px 20px; text-decoration: none; text-align: left;\">\n",
    "    <span style=\"display: block; font-size: 12px; color: #666; margin-bottom: 4px;\">Previous</span>\n",
    "    <span style=\"display: block; font-size: 16px; font-weight: 600; color: #1a5276;\">« Why Migrate to Databricks</span>\n",
    "  </a>\n",
    "  <a href=\"$./0.3 - Architecture and Feature Mapping\" style=\"flex: 1; border: 1px solid #e0e0e0; border-radius: 8px; padding: 16px 20px; text-decoration: none; text-align: right;\">\n",
    "    <span style=\"display: block; font-size: 12px; color: #666; margin-bottom: 4px;\">Next</span>\n",
    "    <span style=\"display: block; font-size: 16px; font-weight: 600; color: #1a5276;\">Architecture and Feature Mapping »</span>\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbc8ddbd-93fb-4ccb-aaee-169413804083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0.2 - Migration Maturity Model",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
